# -*- coding: utf-8 -*-
"""BinClassMod.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ivY4e_0JnMGG5yifcYUbWOxbjcsHgV1u
"""
"""
El propòsit del programari és crear un model per predir amb les
especificacions d’un tumor de mama com a paràmetres, si aquest és benigne
o maligne, fent ús d’una xarxa neuronal de classificació binària.
El conjunt de dades es pot trobar a:
https://www.kaggle.com/datasets/yasserh/breast-cancer-dataset
"""
#Importa la llibreria “pandas”, la principal característica de la 
#qual és la gestió i la modificació de conjunts de dades.
import pandas as pd
#Importa de la llibreria “sklearn”, el mòdul “preprocessing”, el qual
#ajuda amb el formatatge de les dades.
from sklearn import preprocessing
#Importa de la llibreria “sklearn”, el mòdul “train_test_split”, el
#qual ajuda amb la separació de dades.
from sklearn.model_selection import train_test_split
#Importa de la llibreria “tensorflow”, la classe“Sequential”, la qual
#compilar crear les capes del model.
from tensorflow.keras.models import Sequential
#Importa de la llibreria “tensorflow”, la classe“Dense”, la qual
#permet crear les capes interconnectades del model.
from tensorflow.keras.layers import Dense

#Importa el CSV on estan les dades, i la llibreria “pandas” ho llegeix,
#transformant-ho en una “array”, format compatible amb les altres
#llibreries. 
dataset = pd.read_csv("/content/breast-cancer.csv")
#Es desfà de la columna “id”, atès que aquesta no aporta informació de
#l'estat de l'individu.
dataset = dataset.drop("id", axis = 1)
#Codifica l'etiqueta perquè sigui representada numèricament.
#("M"->1, "B"->0)
label = preprocessing.LabelEncoder()
dataset["diagnosis"] = label.fit_transform(dataset["diagnosis"])
#Crea un subconjunt de les dades on només les respostes són 
#emmagatzemades.
y = dataset["diagnosis"]
#Crea un subconjunt de totes les dades, excepte les respostes.
x = dataset.drop("diagnosis", axis = 1)

#Normalitza tota els paràmetres usant la fórmula estàndard.
mean = x.mean(axis=0)
x -= mean
std = x.std(axis = 0)
x /= std

#Usant el mòdul de “sklearn”, es fan subconjunts de les dades, en funció
#del seu propòsit. Es dedica el 75% a entrenar el model, i el 25%
#a l’examinació d’aquest.
x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.25, random_state=42)

#Usant el mòdul de “tensorflow”, s’inicialitza el model, tenint en 
#compte que aquest serà seqüencial. I
model = Sequential()
#S’afegeix la capa d’entrada, comptant amb 30 nodes, replicant així el 
#nombre de paràmetres.
model.add(Dense(30, input_dim = 30, activation = "relu"))
#S’afegeix una capa oculta amb 10 nodes, usant d’activació la funció 
#d’unitat lineal rectificada.
model.add(Dense(10, activation = "relu"))
#S’afegeix una capa de sortida, amb un sol node, usant la funció sigmoide
#com a activació.
model.add(Dense(1, activation = "sigmoid"))
#Compila el model, establint la pèrdua d'entropia creuada com a funció
#d’aquesta, un mètode de descens de gradient estocàstic(adam) com a 
#optimitzador, i les mètriques se centren la precisió del model.
model.compile(loss = "binary_crossentropy", optimizer = "adam", metrics = ["accuracy"])

#Entrena el model amb els subconjunts prèviament separats, repassant 
#el mateix conjunt de dades 100 cops.
model.fit(x = x_train, y = y_train, epochs = 100)

##Retorna la pèrdua i la precisió del model després d’examinar-se en els 
#subconjunts dedicats a l’examinació.
loss, accuracy = model.evaluate(x = x_test, y = y_test)